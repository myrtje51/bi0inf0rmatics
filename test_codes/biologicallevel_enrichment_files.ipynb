{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:217: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sstats\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "class ProteinSet(object):\n",
    "    def __init__(self, proteindict, database):\n",
    "        \"\"\"\n",
    "        Function: \n",
    "        Making a global variable of the variables that are gonna be used through the whole class. \n",
    "        \n",
    "        Variables: \n",
    "        self.proteindict = a dictionary with a term and a list of proteins per item. \n",
    "        self.database = the name of the database. \n",
    "        \"\"\"\n",
    "        self.proteindict = { name : set(p) for name, p in proteindict.items() }\n",
    "        self.database = database\n",
    "    \n",
    "    def enrich(self, otherset, background):\n",
    "        \"\"\"\n",
    "        Function: \n",
    "        This function takes 3 sets of proteins (or genes) and uses them to make an enrichment using either fisher's exact test or \n",
    "        the chi2 (depending on how big the sets are). \n",
    "        \n",
    "        Variables: \n",
    "        list_res = a list with lists that will later be turned into a dataframe. Eech list within the list will have information\n",
    "        about a row in the table. \n",
    "        name = the name of the drug \n",
    "        pset = a set of proteins that are targets of the drug. \n",
    "        term = the name in a list. \n",
    "        proteins = the proteins in a list. \n",
    "        results = the enrichment results in a NamedTuple. \n",
    "        l_results = the enrichment results turned into a list. \n",
    "        joined = the name of the database and the term merged with the l_results list. \n",
    "        df_final = a dataframe with all the enrichment results. \n",
    "        \"\"\"\n",
    "        list_res = []\n",
    "        for name, pset in self.proteindict.items():\n",
    "            term = [self.database] + [name] \n",
    "            proteins = list(pset)\n",
    "            results = self.set_enrichment(pset, otherset, background)\n",
    "            l_results = list(results)\n",
    "            joined = term + l_results\n",
    "            joined.append(proteins)\n",
    "            list_res.append(joined)\n",
    "        \n",
    "        df_final = pd.DataFrame(list_res)\n",
    "        df_final.columns = ['Database', 'Name', 'oddsratio', 'c2statistic', 'pvalue', 'table', 'method', 'proteins'] \n",
    "        return df_final\n",
    "    \n",
    "    def set_enrichment(self, your_set, other_set, universe, abcd_values=False):\n",
    "    \n",
    "        resTuple = namedtuple(\"setEnrichmentResult\", [ 'oddsratio', 'c2statistic', 'pvalue', 'table', 'method'])\n",
    "\n",
    "        universe  = set(universe)\n",
    "        your_set  = set(your_set) & universe\n",
    "        other_set = set(other_set) & universe\n",
    "\n",
    "        a = your_set & other_set\n",
    "        b = other_set - your_set\n",
    "        c = your_set - other_set\n",
    "        d = universe - (your_set | other_set)\n",
    "\n",
    "        table = [ [len(a), len(b)], [len(c), len(d)]]\n",
    "        if min(min(table)) <= 5:\n",
    "            method = 'fisher'\n",
    "            oddsratio, p = sstats.fisher_exact(table)\n",
    "            chi2 = None\n",
    "        else:\n",
    "            method = 'chi2'\n",
    "            chi2, p, dof, expected = sstats.chi2_contingency(table)\n",
    "            oddsratio = 100\n",
    "            if table[1][0] > 0 and table[0][1] > 0:\n",
    "                oddsratio = table[0][0] * table[1][1] / (table[1][0] * table[0][1])\n",
    "            else:\n",
    "                oddsratio = np.inf\n",
    "\n",
    "        if abcd_values:\n",
    "            return resTuple(oddsratio, chi2, p, [[a,b],[c,d]], method)\n",
    "        else:\n",
    "            return resTuple(oddsratio, chi2, p, table, method)\n",
    "        \n",
    "def protein_to_entrez(other_set1): \n",
    "    \"\"\"\n",
    "    Function: \n",
    "    This function takes a dataset containing ensembl protein id's and turns them into entrez gene id's. \n",
    "    \n",
    "    Variables: \n",
    "    biomart_data = a dataset with entrez gene id's and their corresponding ensembl protein id's. \n",
    "    other_set1 = a list of entrez gene id's. \n",
    "    get_ens = merged dataset with other_set1 and biomart_data. \n",
    "    get_ens_filtered = the same dataset as get_ens but without some of the columns that are not important. \n",
    "    \"\"\"\n",
    "    biomart_data = pd.read_csv(\"biomart.tsv\", \n",
    "                  sep='\\t', \n",
    "                  names=[\"gene\", \"transcript\", \"protein\", \"Entrez\", \"Uniprot\", \"name\"])\n",
    "\n",
    "    get_ens = pd.merge(other_set1, biomart_data, on=[\"protein\"]) \n",
    "    get_ens = get_ens.dropna(subset=['Entrez'])\n",
    "    get_ens['Entrez'] = get_ens['Entrez'].astype(int)\n",
    "    get_ens_filtered = get_ens.drop([\"gene\", \"transcript\", \"Uniprot\"], axis=1)\n",
    "    \n",
    "    return get_ens_filtered\n",
    "\n",
    "def make_dictio_DT(): \n",
    "    \"\"\"\n",
    "    Function: \n",
    "    This function makes a dictionary with a drug and a list of proteins that are targets of that drug.\n",
    "    \n",
    "    Variable: \n",
    "    mapped = dataset with drugs and their targets. \n",
    "    dictio = a dictionary with a drug and the corresponding targets (proteins).\n",
    "    \"\"\"\n",
    "    mapped = pd.read_csv('mapped_DB_STITCH.tsv', sep='\\t')\n",
    "    mapped['protein'] = mapped['protein'].map(lambda x: x.lstrip('9606.'))\n",
    "    mapped = mapped[['CID', 'InChIKey', 'DrugBank ID', 'Name', 'protein', 'combined_score']].drop_duplicates()\n",
    "    \n",
    "    get_entr_filtered = protein_to_entrez(mapped)\n",
    "    \n",
    "    dictio = {}\n",
    "    for i in get_entr_filtered['Name'].unique(): \n",
    "        dictio[i] = [get_entr_filtered['Entrez'][j] for j in get_entr_filtered[get_entr_filtered['Name']==i].index]\n",
    "    \n",
    "    return dictio \n",
    "\n",
    "def KEGG_data(): \n",
    "    \"\"\"\n",
    "    Function: \n",
    "    Reads in the enrichment results of the first enrichment and turns it into a dictionary. \n",
    "    \n",
    "    Variable:\n",
    "    KEGG_ACR_results = reads in the enrichment results of the first enrichment. \n",
    "    empty_lijst_KEGG = list of gene ID's per KEGG pathway. \n",
    "    per_pathway = list of gene ID's per KEGG pathway.\n",
    "    gene_list = the gene ID's seperated by '/'\n",
    "    dictionary = a dictionary with the KEGG pathway and the list of gene ID's that have something to do with the \n",
    "    KEGG pathway. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    KEGG_ACR_results = pd.read_csv(\"KEGGACR_enrichment_results.csv\")\n",
    "    \n",
    "    empty_lijst_KEGG = []\n",
    "    for x in KEGG_ACR_results['geneID']:\n",
    "        per_pathway = []\n",
    "        gene_list = x.split(\"/\")\n",
    "        per_pathway += gene_list\n",
    "        per_pathway = list(map(int, per_pathway))\n",
    "        empty_lijst_KEGG.append(per_pathway)\n",
    "    KEGG_ACR_results['listID'] = empty_lijst_KEGG\n",
    "    \n",
    "    dictionary = {} \n",
    "    for index, row in KEGG_ACR_results.iterrows():\n",
    "        dictionary[row['ID']] = row['listID']\n",
    "        \n",
    "    return dictionary\n",
    "\n",
    "def GO_BP_data(): \n",
    "    \"\"\"\n",
    "    Function: \n",
    "    Reads in the enrichment results of the first enrichment and turns it into a dictionary. \n",
    "    \n",
    "    Variable: \n",
    "    GO_BP_ACR_results = reads in enrichment results of the first enrichment. \n",
    "    empty_lijst_GO_BP = list of gene ID's per biological process. \n",
    "    per_pathway = list of gene ID's for one biological process. \n",
    "    gene_list = the gene ID's seperated by '/'\n",
    "    dictionary = a dictionary with the biological process and the list of gene ID's that have something to do with \n",
    "    the biological process. \n",
    "    \"\"\"\n",
    "        \n",
    "    GO_BP_ACR_results = pd.read_csv(\"GO_BPACR_enrichment_results.csv\")\n",
    "    \n",
    "    empty_lijst_GO_BP = []\n",
    "    for x in GO_BP_ACR_results['geneID']:\n",
    "        per_pathway = []\n",
    "        gene_list = x.split(\"/\")\n",
    "        per_pathway += gene_list\n",
    "        per_pathway = list(map(int, per_pathway))\n",
    "        empty_lijst_GO_BP.append(per_pathway)\n",
    "    GO_BP_ACR_results['listID'] = empty_lijst_GO_BP\n",
    "    \n",
    "    dictionary = {} \n",
    "    for index, row in GO_BP_ACR_results.iterrows():\n",
    "        dictionary[row['ID']] = row['listID']\n",
    "        \n",
    "    return dictionary\n",
    "\n",
    "def GO_CC_data():\n",
    "    \"\"\"\n",
    "    Function: \n",
    "    Reads in the enrichment results of the first enrichment and turns it into a dictionary. \n",
    "    \n",
    "    Variable: \n",
    "    GO_CC_ACR_results = reads in the enrichment results. \n",
    "    empty_lijst_GO_CC = list of gene ID's per cellular component. \n",
    "    per_pathway = list of gene ID's for one cellular component. \n",
    "    gene_list = the gene ID's seperated by '/'. \n",
    "    dictionary = a dictionary with the cellular component and the list of gene ID's that have something to do with \n",
    "    the cellular component. \n",
    "    \"\"\"\n",
    "            \n",
    "    GO_CC_ACR_results = pd.read_csv(\"GO_CCACR_enrichment_results.csv\")\n",
    "    \n",
    "    empty_lijst_GO_CC = []\n",
    "    for x in GO_CC_ACR_results['geneID']:\n",
    "        per_pathway = []\n",
    "        gene_list = x.split(\"/\")\n",
    "        per_pathway += gene_list\n",
    "        per_pathway = list(map(int, per_pathway))\n",
    "        empty_lijst_GO_CC.append(per_pathway)\n",
    "    GO_CC_ACR_results['listID'] = empty_lijst_GO_CC\n",
    "    \n",
    "    dictionary = {} \n",
    "    for index, row in GO_CC_ACR_results.iterrows():\n",
    "        dictionary[row['ID']] = row['listID']\n",
    "        \n",
    "    return dictionary\n",
    "\n",
    "def GO_MF_data(): \n",
    "    \"\"\"\n",
    "    Function:\n",
    "    Reads in the enrichment results of the first enrichment and turns it into a dictionary. \n",
    "    \n",
    "    Variable: \n",
    "    GO_MF_ACR_results = reads in the enrichment results. \n",
    "    empty_lijst_GO_MF = list of gene ID's per molecular function.\n",
    "    per_pathway = list of gene ID's for one molecular function. \n",
    "    gene_list = the gene ID's seperated by '/'\n",
    "    dictionary = dictionary with the molecular function and the list of gene ID's. \n",
    "    \"\"\"\n",
    "    \n",
    "    GO_MF_ACR_results = pd.read_csv(\"GO_MFACR_enrichment_results.csv\")\n",
    "    \n",
    "    empty_lijst_GO_MF = []\n",
    "    for x in GO_MF_ACR_results['geneID']:\n",
    "        per_pathway = []\n",
    "        gene_list = x.split(\"/\")\n",
    "        per_pathway += gene_list\n",
    "        per_pathway = list(map(int, per_pathway))\n",
    "        empty_lijst_GO_MF.append(per_pathway)\n",
    "    GO_MF_ACR_results['listID'] = empty_lijst_GO_MF\n",
    "    \n",
    "    dictionary = {} \n",
    "    for index, row in GO_MF_ACR_results.iterrows():\n",
    "        dictionary[row['ID']] = row['listID']\n",
    "        \n",
    "    return dictionary\n",
    "\n",
    "def reactome_data():\n",
    "    \"\"\"\n",
    "    Function: \n",
    "    Reads in the enrichment results of the first enrichment and turns it into a dictionary. \n",
    "    \n",
    "    Variable: \n",
    "    reactome_ACR_results = reads in the dataset with the results of the first enrichment. \n",
    "    biomart_data = reads in the dataset with biomart data. \n",
    "    empty_lijst_reactome = list of gene ID's per pathway. \n",
    "    dictionary = a dictionary with a pathway and a list of genes that have something to do with that pathway.\n",
    "    \"\"\"\n",
    "    \n",
    "    reactome_ACR_results = pd.read_csv(\"reactomeACR_enrichment_results.csv\")\n",
    "    \n",
    "    biomart_data = pd.read_csv(\"biomart.tsv\", \n",
    "                  sep='\\t', \n",
    "                  names=[\"gene\", \"transcript\", \"protein\", \"Entrez\", \"Uniprot\", \"name\"])\n",
    "    \n",
    "    empty_lijst_reactome = []\n",
    "    for x in reactome_ACR_results['geneID']:\n",
    "        per_pathway = []\n",
    "        gene_list = x.split(\"/\")\n",
    "        biomart_filtered = biomart_data[biomart_data['name'].isin(gene_list)]\n",
    "        biomart_filtered['Entrez']=biomart_filtered['Entrez'].astype(int)\n",
    "        just_entrez = list(biomart_filtered['Entrez'].unique()) \n",
    "        per_pathway += just_entrez\n",
    "        empty_lijst_reactome.append(per_pathway)\n",
    "    reactome_ACR_results['listID'] = empty_lijst_reactome\n",
    "    \n",
    "    dictionary = {} \n",
    "    for index, row in reactome_ACR_results.iterrows():\n",
    "        dictionary[row['ID']] = row['listID']\n",
    "        \n",
    "    return dictionary\n",
    "\n",
    "def entrez_to_protein(other_set1): \n",
    "    \"\"\"\n",
    "    Function: \n",
    "    This function takes a dataset containing Entrez gene id's and turns them into ensembl protein id's. \n",
    "    \n",
    "    Variables: \n",
    "    biomart_data = a dataset with entrez gene id's and their corresponding ensembl protein id's. \n",
    "    other_set1 = a list of entrez gene id's. \n",
    "    get_ens = merged dataset with other_set1 and biomart_data. \n",
    "    get_ens_filtered = the same dataset as get_ens but without some of the columns that are not important. \n",
    "    \"\"\"\n",
    "    biomart_data = pd.read_csv(\"biomart.tsv\", \n",
    "                  sep='\\t', \n",
    "                  names=[\"gene\", \"transcript\", \"protein\", \"Entrez\", \"Uniprot\", \"name\"])\n",
    "\n",
    "    get_ens = pd.merge(other_set1, biomart_data, on=[\"Entrez\"]) \n",
    "    get_ens = get_ens.dropna(subset=['protein'])\n",
    "    get_ens_filtered = get_ens.drop([\"gene\", \"transcript\", \"Uniprot\"], axis=1)\n",
    "    \n",
    "    return get_ens_filtered\n",
    "\n",
    "def main_ACR_DT():\n",
    "    \"\"\"\n",
    "    Function: \n",
    "    This function calls all the functions and reads in the universe for the enrichment. \n",
    "    \n",
    "    Variables: \n",
    "    ensembl = the universe used for the enrichment. \n",
    "    dictio = the dictionary of drugs and lists of corresponding targets. \n",
    "    get_ens_filtered = a dataframe with entrez gene id's and their corresponding protein id's. \n",
    "    enrichment_call = calls the class: ProteinSet(dictio)\n",
    "    df = a dataframe with all the enrichment results. \n",
    "    \"\"\"\n",
    "    ensembl = pd.read_csv('STITCH_proteins.txt')\n",
    "    get_entr_filtered_ens = protein_to_entrez(ensembl)\n",
    "    \n",
    "    gene_set = pd.read_csv(\"test_list_genes1.0.txt\")\n",
    "    \n",
    "    dictio = make_dictio_DT()\n",
    "    database = \"Genes\"\n",
    "    enrichment_call = ProteinSet(dictio, database)\n",
    "    df = enrichment_call.enrich(gene_set['Entrez'], get_entr_filtered_ens['Entrez']) \n",
    "    \n",
    "    return df\n",
    "    \n",
    "def read_ppis():\n",
    "    \"\"\"\n",
    "    function: \n",
    "    This function reads in the ppi dataset. \n",
    "    \n",
    "    Variables: \n",
    "    protein_protein = a dataframe with all ppi's that have a higher combined_score than 0.9.\n",
    "    \"\"\"\n",
    "    protein_protein = pd.read_csv('protein_links_v11.0_0.9.tsv', sep=' ')\n",
    "    protein_protein['protein'] = protein_protein['protein'].map(lambda x: x.lstrip('9606.'))\n",
    "    protein_protein['chemical'] = protein_protein['chemical'].map(lambda x: x.lstrip('9606.'))  \n",
    "    \n",
    "    return protein_protein\n",
    "\n",
    "def make_dictio_ppi(protein_protein, get_ensp_filtered):\n",
    "    \"\"\"\n",
    "    Function: \n",
    "    This function maps the ppi dataset and the ageing related genes so that it can be enriched later on. \n",
    "    \n",
    "    Variables: \n",
    "    dictio = a dictionary with proteins and a list of proteins that interact with this protein. \n",
    "    filtered_protein = the column with target proteins from the protein_protein dataset filtered by the ageing related genes. \n",
    "    filtered_chemical = the column with the initial protein from the protein_protein dataset filtered by the ageing related \n",
    "    genes. \n",
    "    total = filtered_protein and filtered_chemical put together into one dataset.\n",
    "    protein_gene = converts the protein column of the total dataframe to gene Entrez ID's. \n",
    "    biomart_data = a dataframe with all the data from biomart. \n",
    "    get_ens = merges the biomart dataset and the protein_gene dataset to get the Entrez ID's for the chemicals. \n",
    "    chem_prot_gene = a dataframe with Entrez ID's for the proteins. \n",
    "    dictio = a dictionary with genes and a list of genes that that gene interacts with. \n",
    "    \"\"\"\n",
    "    dictio = {}\n",
    "    filtered_protein = protein_protein[protein_protein['protein'].isin(get_ensp_filtered['protein'])]\n",
    "    filtered_chemical = protein_protein[protein_protein['chemical'].isin(get_ensp_filtered['protein'])]\n",
    "    total = pd.concat([filtered_protein, filtered_chemical], ignore_index=True) \n",
    "    \n",
    "    protein_gene = protein_to_entrez(total)\n",
    "    protein_gene = protein_gene.rename(columns={\"Entrez\": \"Entrez_protein\"})\n",
    "    \n",
    "    biomart_data = pd.read_csv(\"biomart.tsv\", \n",
    "                  sep='\\t', \n",
    "                  names=[\"gene\", \"transcript\", \"chemical\", \"Entrez_chemical\", \"Uniprot\", \"name\"])\n",
    "\n",
    "    get_ens = pd.merge(protein_gene, biomart_data, on=[\"chemical\"]) \n",
    "    get_ens = get_ens.dropna(subset=['Entrez_chemical'])\n",
    "    get_ens['Entrez_chemical'] = get_ens['Entrez_chemical'].astype(int)\n",
    "    chem_prot_gene = get_ens.drop([\"gene\", \"transcript\", \"Uniprot\"], axis=1)\n",
    "    \n",
    "    for i in chem_prot_gene['Entrez_chemical'].unique(): \n",
    "        dictio[i] = [chem_prot_gene['Entrez_protein'][j] for j in chem_prot_gene[chem_prot_gene['Entrez_chemical']==i].index] \n",
    "    \n",
    "    for x in chem_prot_gene['Entrez_protein'].unique():\n",
    "        if x in dictio:\n",
    "            dictio[x] += ([chem_prot_gene['Entrez_chemical'][y] for y in chem_prot_gene[chem_prot_gene['Entrez_protein']==x].index]) \n",
    "        else: \n",
    "            dictio[x] = [chem_prot_gene['Entrez_chemical'][y] for y in chem_prot_gene[chem_prot_gene['Entrez_protein']==x].index]\n",
    "    \n",
    "    return dictio \n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Function:\n",
    "    This function calls all the different functions that make the first enrichment. It then enriches all the \n",
    "    gene-lists for every biological term against the target-lists for every drug. The results are put into a \n",
    "    dataframe. \n",
    "    \n",
    "    Variables: \n",
    "    ensembl = reads the dataset containing the STITCH proteins. \n",
    "    get_entr_filtered_ens = converts the protein ID's to Entrez gene ID's. \n",
    "    gene_set = reads the dataset with the list of aging related genes (Entrez gene ID's). \n",
    "    get_ensp_filtered = the same list as the above but the ID's converted to ensembl protein ID's. \n",
    "    protein_protein = calls the function: read_ppis(). \n",
    "    KEGG_results = calls the function: KEGG_data().\n",
    "    GO_BP_results = calls the function: GO_BP_data(). \n",
    "    GO_CC_results = calls the function: GO_CC_data(). \n",
    "    GO_MF_results = calls the function: GO_MF_data(). \n",
    "    reactome_results = calls the function: reactome_data().\n",
    "    ppi_results = calls the function: make_dictio_ppi() and gives the variables protein_protein and get_ensp_filtered \n",
    "    as input. \n",
    "    databases = a list with all the results of the first enrichment for each of the biological levels. \n",
    "    db_names = a list with all the names of the databases. \n",
    "    dictio_drugs = the dictionary with all the drugs and their targets. \n",
    "    PS = calls the class: ProteinSet. Uses the databases list and the db_names list as input.\n",
    "    super_x = list with enrichment results. \n",
    "    df = dataframe with enrichemtn results. The best p-value gets chosen. \n",
    "    dfObj = all the lists appended to the dataframe. \n",
    "    drug_genes_results = calls the function: main_ACR_DT()\n",
    "    \"\"\"\n",
    "    \n",
    "    ensembl = pd.read_csv('STITCH_proteins.txt')\n",
    "    get_entr_filtered_ens = protein_to_entrez(ensembl)\n",
    "    \n",
    "    gene_set = pd.read_csv(\"test_list_genes1.0.txt\")\n",
    "    get_ensp_filtered = entrez_to_protein(gene_set)\n",
    "    protein_protein = read_ppis()\n",
    "    \n",
    "    KEGG_results = KEGG_data()\n",
    "    GO_BP_results = GO_BP_data()\n",
    "    GO_CC_results = GO_CC_data()\n",
    "    GO_MF_results = GO_MF_data()\n",
    "    reactome_results = reactome_data()\n",
    "    ppi_results = make_dictio_ppi(protein_protein, get_ensp_filtered)\n",
    "    \n",
    "    databases = [KEGG_results, GO_BP_results, GO_CC_results, GO_MF_results, reactome_results, ppi_results]\n",
    "    db_names  = ['KEGG', 'GO_BP', 'GO_CC', 'GO_MF', 'Reactome', 'STRING']\n",
    "    \n",
    "    dictio_drugs = make_dictio_DT()\n",
    "    \n",
    "    PS = [ProteinSet(db,name) for (db,name) in zip(databases, db_names)]\n",
    "    \n",
    "    super_x = []\n",
    "    for drugs, targets in dictio_drugs.items():\n",
    "        df = pd.concat([ps.enrich(targets, get_entr_filtered_ens['Entrez']) for ps in PS])\n",
    "        df['drug'] = drugs\n",
    "        df = df.sort_values(\"pvalue\").groupby(\"Database\", as_index=False).first() \n",
    "        super_x.append(df)\n",
    "    dfObj = pd.concat(super_x)\n",
    "    drug_genes_results = main_ACR_DT()\n",
    "    return dfObj\n",
    "        \n",
    "data = main() \n",
    "\n",
    "#main_ACR_DT()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dbd883db58b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
