{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Entrez          protein     name\n",
      "0       4000  ENSP00000357284     LMNA\n",
      "1       4000  ENSP00000357283     LMNA\n",
      "2       4000  ENSP00000357282     LMNA\n",
      "3       4000  ENSP00000395597     LMNA\n",
      "4       4000  ENSP00000424518     LMNA\n",
      "5       4000  ENSP00000357280     LMNA\n",
      "6       4000  ENSP00000426535     LMNA\n",
      "7       4000  ENSP00000421821     LMNA\n",
      "8       4000  ENSP00000424977     LMNA\n",
      "9       4000  ENSP00000292304     LMNA\n",
      "10      4000  ENSP00000355292     LMNA\n",
      "11      4000  ENSP00000376164     LMNA\n",
      "12    128178  ENSP00000405815  EDARADD\n",
      "13    128178  ENSP00000335076  EDARADD\n",
      "14    128178  ENSP00000352320  EDARADD\n",
      "15       348  ENSP00000252486     APOE\n",
      "16       348  ENSP00000413135     APOE\n",
      "17       348  ENSP00000413653     APOE\n",
      "18       348  ENSP00000410423     APOE\n",
      "19      7124  ENSP00000389265      TNF\n",
      "20      7124  ENSP00000365290      TNF\n",
      "21      7124  ENSP00000410668      TNF\n",
      "22      7124  ENSP00000372988      TNF\n",
      "23      7124  ENSP00000392858      TNF\n",
      "24      7124  ENSP00000389492      TNF\n",
      "25      7124  ENSP00000389490      TNF\n",
      "26      7124  ENSP00000398698      TNF\n",
      "27      2064  ENSP00000462438    ERBB2\n",
      "28      2064  ENSP00000462808    ERBB2\n",
      "29      2064  ENSP00000404047    ERBB2\n",
      "...      ...              ...      ...\n",
      "8090   10801  ENSP00000465173    SEPT9\n",
      "8091   10801  ENSP00000460394    SEPT9\n",
      "8092   10801  ENSP00000466053    SEPT9\n",
      "8093   10801  ENSP00000466539    SEPT9\n",
      "8094   10801  ENSP00000467586    SEPT9\n",
      "8095   10801  ENSP00000465012    SEPT9\n",
      "8096   10801  ENSP00000458910    SEPT9\n",
      "8097   10801  ENSP00000468066    SEPT9\n",
      "8098   10801  ENSP00000459494    SEPT9\n",
      "8099   10801  ENSP00000468567    SEPT9\n",
      "8100   10801  ENSP00000466836    SEPT9\n",
      "8101   10801  ENSP00000465233    SEPT9\n",
      "8102   10801  ENSP00000467327    SEPT9\n",
      "8103   10801  ENSP00000464714    SEPT9\n",
      "8104   10801  ENSP00000465700    SEPT9\n",
      "8105   10801  ENSP00000465031    SEPT9\n",
      "8106   10801  ENSP00000466790    SEPT9\n",
      "8107   10801  ENSP00000458668    SEPT9\n",
      "8108   10801  ENSP00000467352    SEPT9\n",
      "8109   10801  ENSP00000467408    SEPT9\n",
      "8110   10801  ENSP00000465384    SEPT9\n",
      "8111   10801  ENSP00000467973    SEPT9\n",
      "8112   10801  ENSP00000468554    SEPT9\n",
      "8113   10801  ENSP00000466540    SEPT9\n",
      "8114   10801  ENSP00000465458    SEPT9\n",
      "8115   10801  ENSP00000467049    SEPT9\n",
      "8116   10801  ENSP00000467068    SEPT9\n",
      "8117   10801  ENSP00000461593    SEPT9\n",
      "8118   10801  ENSP00000464859    SEPT9\n",
      "8119   10801  ENSP00000464947    SEPT9\n",
      "\n",
      "[8120 rows x 3 columns]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-98c43418991d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfObj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m \u001b[0mmain_ppi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;31m#main_ACR_DT()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-98c43418991d>\u001b[0m in \u001b[0;36mmain_ppi\u001b[1;34m()\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[0mget_ensp_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprotein_to_entrez\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgene_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_ensp_filtered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m     \u001b[0mppi_dictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_dictio_ppi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotein_protein\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_ensp_filtered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m     \u001b[0mdictio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_dictio_DT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[0mppi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"STRING\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-98c43418991d>\u001b[0m in \u001b[0;36mmake_dictio_ppi\u001b[1;34m(protein_protein, get_ensp_filtered)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'chemical'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mdictio\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'protein'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'chemical'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'protein'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2916\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2917\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2918\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2920\u001b[0m         \u001b[1;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2966\u001b[0m         \u001b[1;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2967\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2968\u001b[1;33m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2969\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sstats\n",
    "import pandas as pd \n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "class ProteinSet(object):\n",
    "    def __init__(self, proteindict, database):\n",
    "        \"\"\"\n",
    "        Function: \n",
    "        Making a global variable of the variables that are gonna be used through the whole class. \n",
    "        \n",
    "        Variables: \n",
    "        self.proteindict = a dictionary with a term and a list of proteins per item. \n",
    "        self.database = the name of the database. \n",
    "        \"\"\"\n",
    "        self.proteindict = { name : set(p) for name, p in proteindict.items() }\n",
    "        self.database = database\n",
    "    \n",
    "    def enrich(self, otherset, background):\n",
    "        \"\"\"\n",
    "        Function: \n",
    "        This function takes 3 sets of proteins (or genes) and uses them to make an enrichment using either fisher's exact test or \n",
    "        the chi2 (depending on how big the sets are). \n",
    "        \n",
    "        Variables: \n",
    "        list_res = a list with lists that will later be turned into a dataframe. Eech list within the list will have information\n",
    "        about a row in the table. \n",
    "        name = the name of the drug \n",
    "        pset = a set of proteins that are targets of the drug. \n",
    "        term = the name in a list. \n",
    "        proteins = the proteins in a list. \n",
    "        results = the enrichment results in a NamedTuple. \n",
    "        l_results = the enrichment results turned into a list. \n",
    "        joined = the name of the database and the term merged with the l_results list. \n",
    "        df_final = a dataframe with all the enrichment results. \n",
    "        \"\"\"\n",
    "        list_res = []\n",
    "        for name, pset in self.proteindict.items():\n",
    "            term = [self.database] + [name] \n",
    "            proteins = list(pset)\n",
    "            results = self.set_enrichment(pset, otherset, background)\n",
    "            l_results = list(results)\n",
    "            joined = term + l_results\n",
    "            joined.append(proteins)\n",
    "            list_res.append(joined)\n",
    "        \n",
    "        df_final = pd.DataFrame(list_res)\n",
    "        df_final.columns = ['Database', 'Name', 'oddsratio', 'c2statistic', 'pvalue', 'table', 'method', 'proteins'] \n",
    "        return df_final\n",
    "    \n",
    "    def set_enrichment(self, your_set, other_set, universe, abcd_values=False):\n",
    "    \n",
    "        resTuple = namedtuple(\"setEnrichmentResult\", [ 'oddsratio', 'c2statistic', 'pvalue', 'table', 'method'])\n",
    "\n",
    "        universe  = set(universe)\n",
    "        your_set  = set(your_set) & universe\n",
    "        other_set = set(other_set) & universe\n",
    "\n",
    "        a = your_set & other_set\n",
    "        b = other_set - your_set\n",
    "        c = your_set - other_set\n",
    "        d = universe - (your_set | other_set)\n",
    "\n",
    "        table = [ [len(a), len(b)], [len(c), len(d)]]\n",
    "        if min(min(table)) <= 5:\n",
    "            method = 'fisher'\n",
    "            oddsratio, p = sstats.fisher_exact(table)\n",
    "            chi2 = None\n",
    "        else:\n",
    "            method = 'chi2'\n",
    "            chi2, p, dof, expected = sstats.chi2_contingency(table)\n",
    "            oddsratio = 100\n",
    "            if table[1][0] > 0 and table[0][1] > 0:\n",
    "                oddsratio = table[0][0] * table[1][1] / (table[1][0] * table[0][1])\n",
    "            else:\n",
    "                oddsratio = np.inf\n",
    "\n",
    "        if abcd_values:\n",
    "            return resTuple(oddsratio, chi2, p, [[a,b],[c,d]], method)\n",
    "        else:\n",
    "            return resTuple(oddsratio, chi2, p, table, method)\n",
    "\n",
    "def make_dictio_DT(): \n",
    "    \"\"\"\n",
    "    Function: \n",
    "    This function makes a dictionary with a drug and a list of proteins that are targets of that drug.\n",
    "    \n",
    "    Variable: \n",
    "    mapped = dataset with drugs and their targets. \n",
    "    dictio = a dictionary with a drug and the corresponding targets (proteins).\n",
    "    \"\"\"\n",
    "    mapped = pd.read_csv('mapped_DB_STITCH.tsv', sep='\\t')\n",
    "    mapped['protein'] = mapped['protein'].map(lambda x: x.lstrip('9606.'))\n",
    "    mapped = mapped[['CID', 'InChIKey', 'DrugBank ID', 'Name', 'protein', 'combined_score']].drop_duplicates()\n",
    "    \n",
    "    dictio = {}\n",
    "    for i in mapped['Name'].unique(): \n",
    "        dictio[i] = [mapped['protein'][j] for j in mapped[mapped['Name']==i].index]\n",
    "    \n",
    "    return dictio \n",
    "\n",
    "def protein_to_entrez(other_set1): \n",
    "    \"\"\"\n",
    "    Function: \n",
    "    This function takes a dataset containing ensembl protein id's and turns them into entrez gene id's. \n",
    "    \n",
    "    Variables: \n",
    "    biomart_data = a dataset with entrez gene id's and their corresponding ensembl protein id's. \n",
    "    other_set1 = a list of entrez gene id's. \n",
    "    get_ens = merged dataset with other_set1 and biomart_data. \n",
    "    get_ens_filtered = the same dataset as get_ens but without some of the columns that are not important. \n",
    "    \"\"\"\n",
    "    biomart_data = pd.read_csv(\"biomart.tsv\", \n",
    "                  sep='\\t', \n",
    "                  names=[\"gene\", \"transcript\", \"protein\", \"Entrez\", \"Uniprot\", \"name\"])\n",
    "\n",
    "    get_ens = pd.merge(other_set1, biomart_data, on=[\"Entrez\"]) \n",
    "    get_ens = get_ens.dropna(subset=['protein'])\n",
    "    get_ens_filtered = get_ens.drop([\"gene\", \"transcript\", \"Uniprot\"], axis=1)\n",
    "    \n",
    "    return get_ens_filtered\n",
    "\n",
    "def main_ACR_DT():\n",
    "    \"\"\"\n",
    "    Function: \n",
    "    This function calls all the functions and reads in the universe for the enrichment. \n",
    "    \n",
    "    Variables: \n",
    "    ensembl = the universe used for the enrichment. \n",
    "    dictio = the dictionary of drugs and lists of corresponding targets. \n",
    "    get_ens_filtered = a dataframe with entrez gene id's and their corresponding protein id's. \n",
    "    enrichment_call = calls the class: ProteinSet(dictio)\n",
    "    df = a dataframe with all the enrichment results. \n",
    "    \"\"\"\n",
    "    ensembl = pd.read_csv('STITCH_proteins.txt')\n",
    "    dictio = make_dictio_DT()\n",
    "    get_ens_filtered = entrez_to_protein() \n",
    "    enrichment_call = ProteinSet(dictio)\n",
    "    df = enrichment_call.enrich(get_ens_filtered['protein'], ensembl['protein']) \n",
    "    #print(df)\n",
    "    \n",
    "def read_ppis():\n",
    "    \"\"\"\n",
    "    function: \n",
    "    This function reads in the ppi dataset. \n",
    "    \n",
    "    Variables: \n",
    "    protein_protein = a dataframe with all ppi's that have a higher combined_score than 0.9.\n",
    "    \"\"\"\n",
    "    protein_protein = pd.read_csv('protein_links_v11.0_0.9.tsv', sep=' ')\n",
    "    protein_protein['protein'] = protein_protein['protein'].map(lambda x: x.lstrip('9606.'))\n",
    "    protein_protein['chemical'] = protein_protein['chemical'].map(lambda x: x.lstrip('9606.')) \n",
    "    #protein_protein = pd.read_csv('string_interactions.tsv', sep='\\t')\n",
    "    #print(protein_protein)\n",
    "    #protein_protein['node2_external_id'] = protein_protein['node2_external_id'].map(lambda x: x.lstrip('9606.'))\n",
    "    #protein_protein['node1_external_id'] = protein_protein['node1_external_id'].map(lambda x: x.lstrip('9606.')) \n",
    "    \n",
    "    return protein_protein\n",
    "\n",
    "def make_dictio_ppi(protein_protein, get_ensp_filtered):\n",
    "    \"\"\"\n",
    "    Function: \n",
    "    This function maps the ppi dataset and the ageing related genes so that it can be enriched later on. \n",
    "    \n",
    "    Variables: \n",
    "    dictio = a dictionary with proteins and a list of proteins that interact with this protein. \n",
    "    filtered_protein = the column with target proteins from the protein_protein dataset filtered by the ageing related genes. \n",
    "    filtered_chemical = the column with the initial protein from the protein_protein dataset filtered by the ageing related \n",
    "    genes. \n",
    "    total = filtered_protein and filtered_chemical put together into one dataset.\n",
    "    \"\"\"\n",
    "    dictio = {}\n",
    "    filtered_protein = protein_protein[protein_protein['protein'].isin(get_ensp_filtered['protein'])]\n",
    "    filtered_chemical = protein_protein[protein_protein['chemical'].isin(get_ensp_filtered['protein'])]\n",
    "    total = pd.concat([filtered_protein, filtered_chemical], ignore_index=True) \n",
    "    \n",
    "    for i in total['chemical'].unique(): \n",
    "        dictio[i] = [total['protein'][j] for j in total[total['chemical']==i].index] \n",
    "    \n",
    "    for x in total['protein'].unique():\n",
    "        if x in dictio:\n",
    "            dictio[x] += ([total['chemical'][y] for y in total[total['protein']==x].index]) \n",
    "        else: \n",
    "            dictio[x] = [total['chemical'][y] for y in total[total['protein']==x].index]\n",
    "    \n",
    "    return dictio \n",
    "    \n",
    "\n",
    "def main_ppi():\n",
    "    \"\"\"\n",
    "    Function: \n",
    "    This function calls all the important functions and gives them variables. \n",
    "    \n",
    "    Variables: \n",
    "    protein_protein = a dataframe of protein protein interactions returned from the read_ppis() function. \n",
    "    get_ensp_filtered = a dataframe of protein ID's that are related to ageing, returned from the get_ensp_filtered() function. \n",
    "    ppi_dictionary = a dictionary with proteins and lists of proteins that interact with this protein, returned from the \n",
    "    make_dictio_ppi() function. \n",
    "    enrichment_call = calls the class: ProteinSet and gives the class the variable: ppi_dictionary. \n",
    "    df = a dataframe with the results of the enrich() function in the class: ProteinSet. \n",
    "    sort_df = sorts the dataframe on the column pvalue. \n",
    "    \"\"\"\n",
    "    ensembl = pd.read_csv('STITCH_proteins.txt')\n",
    "    gene_set = pd.read_csv(\"test_list_genes1.0.txt\")\n",
    "    protein_protein = read_ppis() \n",
    "    get_ensp_filtered = protein_to_entrez(gene_set) \n",
    "    ppi_dictionary = make_dictio_ppi(protein_protein, get_ensp_filtered) \n",
    "    dictio = make_dictio_DT()\n",
    "    ppi = \"STRING\"\n",
    "    enrichment_call = ProteinSet(ppi_dictionary, ppi)\n",
    "    dfObj = pd.DataFrame()\n",
    "    for drugs, targets in dictio.items():\n",
    "        df = enrichment_call.enrich(targets, ensembl['protein'])\n",
    "        df['drug'] = drugs \n",
    "        dfObj = pd.concat([dfObj, df], ignore_index=True)\n",
    "    print(dfObj)\n",
    "\n",
    "main_ppi() \n",
    "\n",
    "#main_ACR_DT()\n",
    "#http://string-db.org/api/tsv/interactionsList?identifiers=9606.ENSP00000304895%0D9606.ENSP00000303830\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
